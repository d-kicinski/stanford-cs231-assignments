{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Load Datasets\n",
    "\n",
    "Load CIFAR10 dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 19000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True,\n",
    "                          transform=T.ToTensor())\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor  # the CPU datatype\n",
    "\n",
    "# Constant to control how grequentl we print train loss\n",
    "print_every = 100\n",
    "\n",
    "# This is a little utility that we'll use to reset the model if we want to\n",
    "# re-initialize all our parameters\n",
    "def reset(m):\n",
    "  if hasattr(m, \"reset_parameters\"):\n",
    "    m.reset_parameters()\n",
    "\n",
    "# define new module which only purpouse is to change dimension of input from\n",
    "# convolusional convinient form into fully-connected convinient\n",
    "class Flatten(nn.Module):\n",
    "  def forward(self, x):\n",
    "    N, C, H, W = x.size()  # read in dims sizes\n",
    "    # 'flatten' the C * H * W values into a single vector pre image\n",
    "    return x.view(N, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Definition of ConvNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Here's where we define the architecture of the model\n",
    "#          Conv2d       Flatten   Linear\n",
    "# (32x32x3) -> (13x13x32) -> (5408) -> 10\n",
    "simple_model = nn.Sequential(\n",
    "             nn.Conv2d(3, 32, kernel_size=7, stride=2),\n",
    "             nn.ReLU(inplace=True),\n",
    "             Flatten(),\n",
    "             nn.Linear(5408, 10),\n",
    "             )\n",
    "\n",
    "# Set the type of all data in this model to be FloatTensor\n",
    "simple_model.type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "# lr sets the learning rate of the optymizer\n",
    "optymizer = optim.Adam(simple_model.parameters(), lr=1e-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "More fancyier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Here's another funny model\n",
    "#          Conv2d       MaxPool   Flatten     Linear    Linear\n",
    "# (32x32x3) -> (26x26x32) -> (13x13x32) -> (5408) -> (1024) -> (10)\n",
    "fixed_model_base = nn.Sequential(\n",
    "                 nn.Conv2d(3, 32, kernel_size=7, stride=1),\n",
    "                 nn.ReLU(inplace=True),\n",
    "                 nn.BatchNorm2d(32, affine=False),\n",
    "                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                 Flatten(),\n",
    "                 nn.Linear(5408, 1024),\n",
    "                 nn.ReLU(inplace=True),\n",
    "                 nn.Linear(1024, 10),\n",
    "                 )\n",
    "\n",
    "# Set the type of all data to be FloarTensor(CPU friendly)\n",
    "fixed_model = fixed_model_base.type(dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "\n",
    "optymizer = optim.RMSprop(fixed_model.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Sanity check - feed random batch into the model defined above and make sure the output is the right size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output shape is:  [64 10]\n",
      "Is valid?  True\n"
     ]
    }
   ],
   "source": [
    "# Sanity check - feed random batch into the model defined above and make sure\n",
    "# the output is the right size\n",
    "x = torch.randn(64, 3, 32, 32).type(dtype)\n",
    "x_var =  Variable(x)  # Construct a PyTorch Variable out of input data\n",
    "ans = fixed_model(x_var)  # Feed it through the model\n",
    "\n",
    "# Check to make sure what comes out of model\n",
    "print(\"The output shape is: \", np.array(ans.size()))\n",
    "print(\"Is valid? \", np.array_equal(np.array(ans.size()), np.array([64, 10])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Time single forward pass just for curiousity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 ms ± 5.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ans = fixed_model(x_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Set model to 'training' mode. This is relevant for soe layers that may have\n",
    "# different behavior in training mode vs testing mode, such as Dropout and BatchNorm\n",
    "fixed_model.train()\n",
    "\n",
    "# Load one batch at time\n",
    "for t, (x, y) in enumerate(loader_train):\n",
    "  x_var = Variable(x.type(dtype))\n",
    "  y_var = Variable(y.type(dtype).long())\n",
    "\n",
    "  # This is a forward pass: predict the scores for each class, for each x in the batch\n",
    "  scores = fixed_model(x_var)\n",
    "\n",
    "  # Use the correct y values and the  predicted y values to compute the loss.\n",
    "  loss = loss_fn(scores, y_var)\n",
    "\n",
    "  if (t + 1) % print_every == 0:\n",
    "    print('t = {0}, loss={\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "name": "explore_pytorch.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
